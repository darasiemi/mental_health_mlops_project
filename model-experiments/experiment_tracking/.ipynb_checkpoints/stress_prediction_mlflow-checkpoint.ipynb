{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0c35ca9-968e-4e41-b3b0-ee26d71fde1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from https://www.kaggle.com/code/ruchitass/predicting-stress-a-machine-learning-approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0d8f36d-fa27-4792-94dc-5e6dbff722a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.9.19\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7e8571a-ba6f-4cf3-94d3-ce1f54d70f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "# Download the stopwords resource\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stemmer = nltk.SnowballStemmer(\"english\")\n",
    "\n",
    "from wordcloud import STOPWORDS\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# from textblob import TextBlob\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "# import nltk\n",
    "# import re\n",
    "# stemmer = nltk.SnowballStemmer(\"english\")\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = stopwords.words('english')\n",
    "# import string\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import kaggle\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import string\n",
    "#Get a list of punctuations\n",
    "punct = []\n",
    "for char in string.punctuation:\n",
    "    punct.append(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31b858a0-ed51-4b75-ac73-dc33d22a7b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "006c8fd0-3949-4ea4-93cf-cc8f12f1aaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "defd4738-b5f3-426f-a84d-9b0c57393236",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import os\n",
    "\n",
    "#os.environ[\"AWS_PROFILE\"] = \"dara\" # fill in with your AWS profile. More info: https://docs.aws.amazon.com/sdk-for-java/latest/developer-guide/setup.html#setup-credentials\n",
    "\n",
    "TRACKING_SERVER_HOST = \"ec2-16-171-53-183.eu-north-1.compute.amazonaws.com\" # fill in with the public DNS of the EC2 instance\n",
    "mlflow.set_tracking_uri(f\"http://{TRACKING_SERVER_HOST}:5000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fce34df0-8ae0-4c17-b69d-a63b5df1eff1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.12.2'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c58520ae-c192-4e8a-a44d-697e59470ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tracking URI: 'http://ec2-16-171-53-183.eu-north-1.compute.amazonaws.com:5000'\n"
     ]
    }
   ],
   "source": [
    "print(f\"tracking URI: '{mlflow.get_tracking_uri()}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236be92f-5bfc-4e73-9b8c-71c09539e848",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e087409-a7e8-4126-b779-fb3e65f683b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../../data/dreaddit-train.csv\")\n",
    "test = pd.read_csv(\"../../data/dreaddit-test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22d983f1-5c7d-447f-9225-dda1c3091c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = [\"lex_liwc_Tone\", \"lex_liwc_i\", \"lex_liwc_negemo\", \"lex_liwc_Clout\", \"sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7cb8c34-7e00-4050-bb26-fd27503e85a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lex_liwc_Tone',\n",
       " 'lex_liwc_i',\n",
       " 'lex_liwc_negemo',\n",
       " 'lex_liwc_Clout',\n",
       " 'sentiment']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5276b067-d1a9-418a-bf71-d65c150bc656",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e27d0ff-2fcb-4a45-8c10-73edaa929ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardization\n",
    "scaler = StandardScaler()\n",
    "# X_numerical = scaler.fit_transform(train_numerical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3177326-9ca8-4ca3-b942-fe2189547a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_numerical_features(df):\n",
    "    X_numerical = df[numerical_columns]\n",
    "    X_numerical = scaler.fit_transform(X_numerical)\n",
    "    return X_numerical\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ccccbf-4918-4e6d-abff-243763b5b5df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c503f91-ec70-48f8-8c30-1edd4bf7b399",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removal(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    text = [w for w in text.split(' ') if w not in stopwords]\n",
    "    text=\" \".join(text)\n",
    "    text = [stemmer.stem(word) for word in text.split(' ')]\n",
    "    text=\" \".join(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "642bd1b0-0348-4726-aa73-03dc73f339b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vect=CountVectorizer(stop_words=\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d8a547d1-9212-4d51-9d00-d2353013d464",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_categorical_features(df, vect = None):\n",
    "    posts = df[[\"text\"]]\n",
    "    posts[\"text\"] = posts[\"text\"].apply(removal)\n",
    "    # posts[\"sentiment\"] = posts[\"text\"].apply(mood)\n",
    "    X = posts[\"text\"]\n",
    "    if vect:\n",
    "        X = vect.transform(X)\n",
    "    else:\n",
    "        vect=CountVectorizer(stop_words=\"english\")\n",
    "        X=vect.fit_transform(X)\n",
    "    return X, vect\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0095fc2a-a44a-433d-8b74-cab6ecee381d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_features(df, vect=None):\n",
    "    X_categorical, vect = process_categorical_features(df, vect)\n",
    "    X_numerical = process_numerical_features(df)\n",
    "    X_combined = np.hstack((X_categorical.toarray(), X_numerical))\n",
    "\n",
    "    return X_combined\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "216faddd-f462-41bf-a8de-98aefcc5c041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_numerical = train[numerical_columns] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6368855b-936f-4f13-b76a-7d9cbf8f7b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_combined = prepare_features(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a906c325-39e7-4986-868b-c3d6f90b8066",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_combined.shape;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3c9aacda-183a-4b7c-9663-13a5f5a9790f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2838, 9448)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_text_features, vect = process_categorical_features(train)\n",
    "X_text_features.toarray().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "264858ff-4744-4f83-bb57-89ca243cc8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9bca96a2-a6d7-4243-90dc-81a7b7c768be",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_combined,x_test_combined,y_train,y_test=train_test_split(X_combined,y,random_state=43)\n",
    "# x_train,x_test,y_train,y_test=train_test_split(train[numerical_columns + categorical_columns],y,random_state=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8355e066-6baf-4748-9386-8661ac9d680b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2838, 9453)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f262d9b4-bce5-4220-92a9-8bdba7a7ca80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_text_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d3b8f771-1c94-4fb9-8169-d1a42c9a38f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_text,x_test_text,y_train,y_test=train_test_split(X_text_features.toarray(),y,random_state=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "36355f79-4e3e-421c-aa8d-a01c79346db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_combined;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d71b21-1b56-4346-aec6-ad56c0252184",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "74200298-d0e0-47ab-98fe-cf3ae6344540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='s3://mlflows-artifacts-remote/1', creation_time=1720770609928, experiment_id='1', last_update_time=1720770609928, lifecycle_stage='active', name='project-experiment-tracking', tags={}>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_name = \"project-experiment-tracking\"\n",
    "mlflow.set_experiment(experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "31b6dc56-6d4d-451c-bec7-bc1150417854",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = mlflow.get_experiment_by_name(experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5230d579-7a7d-4d23-aa1e-8e199e66b884",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_id = experiment.experiment_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "73828864-f318-4836-a669-891206944cbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_id\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "01829b4d-2f0d-404d-9ca4-e270fc40c847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: logistic_reg, Tag: combined Accuracy: 0.7098591549295775\n",
      "Model: logistic_reg, Tag: text_only Accuracy: 0.6746478873239437\n",
      "Model: decision_tree, Tag: combined Accuracy: 0.6605633802816901\n",
      "Model: decision_tree, Tag: text_only Accuracy: 0.6225352112676056\n",
      "Model: random_forest, Tag: combined Accuracy: 0.7450704225352113\n",
      "Model: random_forest, Tag: text_only Accuracy: 0.6605633802816901\n",
      "Model: xgboost, Tag: combined Accuracy: 0.7281690140845071\n",
      "Model: xgboost, Tag: text_only Accuracy: 0.6774647887323944\n"
     ]
    }
   ],
   "source": [
    "# Define your models and datasets\n",
    "models_to_train = [\"logistic_reg\",\"decision_tree\",\"random_forest\",\"xgboost\"]\n",
    "\n",
    "tags = [\"combined\", \"text_only\"]\n",
    "\n",
    "x_data = {\n",
    "    \"train\": {\n",
    "        'combined': x_train_combined,\n",
    "        'text_only': x_train_text\n",
    "    },\n",
    "    \"test\": {\n",
    "        'combined': x_test_combined,\n",
    "        'text_only': x_test_text\n",
    "    }\n",
    "}\n",
    "\n",
    "# Start a new MLflow run for each model\n",
    "for model_name in models_to_train:\n",
    "    for tag in tags:   \n",
    "        with mlflow.start_run(run_name=f\"{model_name}_{tag}\"):\n",
    "            # Initialize the model\n",
    "            if model_name == 'logistic_reg':\n",
    "                model = LogisticRegression(max_iter=1000)\n",
    "            elif model_name == \"decision_tree\":\n",
    "                model = DecisionTreeClassifier()\n",
    "            elif model_name == \"random_forest\":\n",
    "                model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "            elif model_name == \"xgboost\":\n",
    "                model = XGBClassifier(n_estimators=100, random_state=42)\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported model: {model_name}\")\n",
    "\n",
    "            train_data = x_data[\"train\"][tag]\n",
    "            test_data = x_data[\"test\"][tag]\n",
    "            \n",
    "            # Train the model\n",
    "            model.fit(x_data[\"train\"][tag], y_train)\n",
    "            # Predict on the test set\n",
    "            y_pred = model.predict(x_data[\"test\"][tag])\n",
    "            \n",
    "            # Calculate metrics\n",
    "            accuracy = accuracy_score(y_test, y_pred) *100\n",
    "            \n",
    "            # Log parameters and metrics\n",
    "            params = model.get_params()\n",
    "            mlflow.log_params(params)\n",
    "            mlflow.sklearn.log_model(model, f\"model\")\n",
    "            mlflow.log_metric(f\"accuracy_{tag}\", accuracy)\n",
    "\n",
    "            \n",
    "            # Print model evaluation\n",
    "            print(f\"Model: {model_name}, Tag: {tag} Accuracy: {accuracy}\")\n",
    "\n",
    "            # print(f\"default artifacts URI: '{mlflow.get_artifact_uri()}'\")\n",
    "            \n",
    "            # End the MLflow run\n",
    "            mlflow.end_run()\n",
    "            \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b88358-db7f-43ae-ae23-91ee382e3583",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d87925-9e54-47f8-bb8c-7d74535e8e31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c842d2a-1fc9-44e6-bd37-8b6eabc90b9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea71fa5a-373a-4f1e-8929-97025b9558ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426d89b8-0172-4efc-a288-2aaa1a30a5d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
