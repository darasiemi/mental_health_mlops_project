{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c35ca9-968e-4e41-b3b0-ee26d71fde1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from https://www.kaggle.com/code/ruchitass/predicting-stress-a-machine-learning-approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0d8f36d-fa27-4792-94dc-5e6dbff722a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.9.19\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7e8571a-ba6f-4cf3-94d3-ce1f54d70f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "# Download the stopwords resource\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stemmer = nltk.SnowballStemmer(\"english\")\n",
    "\n",
    "from wordcloud import STOPWORDS\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# from textblob import TextBlob\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "# import nltk\n",
    "# import re\n",
    "# stemmer = nltk.SnowballStemmer(\"english\")\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = stopwords.words('english')\n",
    "# import string\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import kaggle\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import string\n",
    "#Get a list of punctuations\n",
    "punct = []\n",
    "for char in string.punctuation:\n",
    "    punct.append(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31b858a0-ed51-4b75-ac73-dc33d22a7b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "006c8fd0-3949-4ea4-93cf-cc8f12f1aaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "defd4738-b5f3-426f-a84d-9b0c57393236",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import os\n",
    "\n",
    "#os.environ[\"AWS_PROFILE\"] = \"dara\" # fill in with your AWS profile. More info: https://docs.aws.amazon.com/sdk-for-java/latest/developer-guide/setup.html#setup-credentials\n",
    "\n",
    "TRACKING_SERVER_HOST = \"ec2-13-48-31-55.eu-north-1.compute.amazonaws.com\" # fill in with the public DNS of the EC2 instance\n",
    "mlflow.set_tracking_uri(f\"http://{TRACKING_SERVER_HOST}:5000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fce34df0-8ae0-4c17-b69d-a63b5df1eff1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.12.2'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c58520ae-c192-4e8a-a44d-697e59470ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tracking URI: 'http://ec2-13-48-31-55.eu-north-1.compute.amazonaws.com:5000'\n"
     ]
    }
   ],
   "source": [
    "print(f\"tracking URI: '{mlflow.get_tracking_uri()}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236be92f-5bfc-4e73-9b8c-71c09539e848",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e087409-a7e8-4126-b779-fb3e65f683b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../../data/dreaddit-train.csv\")\n",
    "test = pd.read_csv(\"../../data/dreaddit-test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22d983f1-5c7d-447f-9225-dda1c3091c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = [\"lex_liwc_Tone\", \"lex_liwc_i\", \"lex_liwc_negemo\", \"lex_liwc_Clout\", \"sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7cb8c34-7e00-4050-bb26-fd27503e85a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lex_liwc_Tone',\n",
       " 'lex_liwc_i',\n",
       " 'lex_liwc_negemo',\n",
       " 'lex_liwc_Clout',\n",
       " 'sentiment']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5276b067-d1a9-418a-bf71-d65c150bc656",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e27d0ff-2fcb-4a45-8c10-73edaa929ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardization\n",
    "scaler = StandardScaler()\n",
    "# X_numerical = scaler.fit_transform(train_numerical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3177326-9ca8-4ca3-b942-fe2189547a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_numerical_features(df):\n",
    "    X_numerical = df[numerical_columns]\n",
    "    X_numerical = scaler.fit_transform(train_numerical)\n",
    "    return X_numerical\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ccccbf-4918-4e6d-abff-243763b5b5df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c503f91-ec70-48f8-8c30-1edd4bf7b399",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removal(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    text = [w for w in text.split(' ') if w not in stopwords]\n",
    "    text=\" \".join(text)\n",
    "    text = [stemmer.stem(word) for word in text.split(' ')]\n",
    "    text=\" \".join(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "642bd1b0-0348-4726-aa73-03dc73f339b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vect=CountVectorizer(stop_words=\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d8a547d1-9212-4d51-9d00-d2353013d464",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_categorical_features(df, vect = None):\n",
    "    posts = train[[\"text\"]]\n",
    "    posts[\"text\"] = posts[\"text\"].apply(removal)\n",
    "    # posts[\"sentiment\"] = posts[\"text\"].apply(mood)\n",
    "    X = posts[\"text\"]\n",
    "    if vect:\n",
    "        print(\"here\")\n",
    "        X = vect.transform(X)\n",
    "    else:\n",
    "        vect=CountVectorizer(stop_words=\"english\")\n",
    "        X=vect.fit_transform(X)\n",
    "    return X, vect\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0095fc2a-a44a-433d-8b74-cab6ecee381d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_features(df, vect=None):\n",
    "    X_categorical, vect = process_categorical_features(train, vect)\n",
    "    X_numerical = process_numerical_features(train)\n",
    "    X_combined = np.hstack((X_categorical.toarray(), X_numerical))\n",
    "\n",
    "    return X_combined\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "216faddd-f462-41bf-a8de-98aefcc5c041",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_numerical = train[numerical_columns] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6368855b-936f-4f13-b76a-7d9cbf8f7b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_combined = prepare_features(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a906c325-39e7-4986-868b-c3d6f90b8066",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_combined.shape;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3c9aacda-183a-4b7c-9663-13a5f5a9790f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2838, 9448)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_text_features, vect = process_categorical_features(train)\n",
    "X_text_features.toarray().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "264858ff-4744-4f83-bb57-89ca243cc8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9bca96a2-a6d7-4243-90dc-81a7b7c768be",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_combined,x_test_combined,y_train,y_test=train_test_split(X_combined,y,random_state=43)\n",
    "# x_train,x_test,y_train,y_test=train_test_split(train[numerical_columns + categorical_columns],y,random_state=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8355e066-6baf-4748-9386-8661ac9d680b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2838, 9453)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f262d9b4-bce5-4220-92a9-8bdba7a7ca80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_text_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d3b8f771-1c94-4fb9-8169-d1a42c9a38f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_text,x_test_text,y_train,y_test=train_test_split(X_text_features.toarray(),y,random_state=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "36355f79-4e3e-421c-aa8d-a01c79346db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_combined;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "74200298-d0e0-47ab-98fe-cf3ae6344540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='s3://mlflows-artifacts-remote/1', creation_time=1720770609928, experiment_id='1', last_update_time=1720770609928, lifecycle_stage='active', name='project-experiment-tracking', tags={}>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# experiment_name = \"project-experiment-tracking\"\n",
    "# mlflow.set_experiment(experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "31b6dc56-6d4d-451c-bec7-bc1150417854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment = mlflow.get_experiment_by_name(experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5230d579-7a7d-4d23-aa1e-8e199e66b884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment_id = experiment.experiment_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "73828864-f318-4836-a669-891206944cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment_id\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a174ae31-7d32-4e97-8025-c660189f42d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9ab20d-9d60-4405-b68e-3d70a785d5fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "abd60341-01b5-4d77-921d-09fef84f317e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████| 15/15 [00:11<00:00,  1.26trial/s, best loss: -0.7253521126760564]\n",
      "Best hyperparameters:  {'max_depth': 18.0, 'min_samples_leaf': 1.0, 'min_samples_split': 6.0, 'n_estimators': 13.0}\n"
     ]
    }
   ],
   "source": [
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "from hyperopt.pyll import scope\n",
    "\n",
    "# Simulate data (use your actual data here)\n",
    "x_combined, y = make_classification(n_samples=1000, n_features=20, random_state=42)\n",
    "\n",
    "# mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "mlflow.set_experiment(\"random-forest-hyperopt\")\n",
    "\n",
    "def objective(params):\n",
    "    with mlflow.start_run():\n",
    "        mlflow.set_tag(\"developer\", \"Dara\")\n",
    "\n",
    "        # Log hyperparameters\n",
    "        for param_name, param_value in params.items():\n",
    "            mlflow.log_param(param_name, param_value)\n",
    "\n",
    "        rf = RandomForestClassifier(**params)\n",
    "        rf.fit(x_train_combined, y_train)\n",
    "        y_pred = rf.predict(x_test_combined)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "\n",
    "    return {'loss': -accuracy, 'status': STATUS_OK}  # Negative because fmin minimizes\n",
    "\n",
    "def run_optimization(num_trials=15):\n",
    "    search_space = {\n",
    "        'max_depth': scope.int(hp.quniform('max_depth', 1, 50, 1)),\n",
    "        'n_estimators': scope.int(hp.quniform('n_estimators', 50, 100, 1)),\n",
    "        'min_samples_split': scope.int(hp.quniform('min_samples_split', 2, 10, 1)),\n",
    "        'min_samples_leaf': scope.int(hp.quniform('min_samples_leaf', 1, 7, 1)),\n",
    "        'random_state': 42\n",
    "    }\n",
    "\n",
    "    rstate = np.random.default_rng(42)  # for reproducible results\n",
    "    trials = Trials()\n",
    "    best = fmin(\n",
    "        fn=objective,\n",
    "        space=search_space,\n",
    "        algo=tpe.suggest,\n",
    "        max_evals=num_trials,\n",
    "        trials=trials,\n",
    "        rstate=rstate\n",
    "    )\n",
    "\n",
    "    print(\"Best hyperparameters: \", best)\n",
    "\n",
    "# Run optimization\n",
    "run_optimization(num_trials=15)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b873c49-040c-419d-afd8-3dba9891b656",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01829b4d-2f0d-404d-9ca4-e270fc40c847",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d87925-9e54-47f8-bb8c-7d74535e8e31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c842d2a-1fc9-44e6-bd37-8b6eabc90b9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea71fa5a-373a-4f1e-8929-97025b9558ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426d89b8-0172-4efc-a288-2aaa1a30a5d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
